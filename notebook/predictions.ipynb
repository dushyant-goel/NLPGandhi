{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d460b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da61166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Word2Vec model\n",
    "model = Word2Vec.load(\"../model/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ba55555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'woman':\n",
      "  young: 0.9201\n",
      "  learned: 0.8548\n",
      "  men: 0.8515\n",
      "  educated: 0.8354\n",
      "  self-sacrificing: 0.8332\n",
      "  noble: 0.8299\n",
      "  old: 0.8279\n",
      "  purdah: 0.8271\n",
      "  child: 0.8238\n",
      "  Men: 0.8234\n",
      "Most similar words to 'India':\n",
      "  America: 0.7999\n",
      "  England: 0.7837\n",
      "  West: 0.7807\n",
      "  country: 0.7798\n",
      "  Hindustan: 0.7794\n",
      "  China: 0.7771\n",
      "  Great: 0.7768\n",
      "  Burma: 0.7702\n",
      "  nation: 0.7697\n",
      "  Europe: 0.7672\n",
      "Most similar words to 'corruption':\n",
      "  recognizing: 0.9701\n",
      "  impossibility: 0.9699\n",
      "  repugnant: 0.9688\n",
      "  criterion: 0.9679\n",
      "  finance: 0.9671\n",
      "  demonstrate: 0.9669\n",
      "  tend: 0.9667\n",
      "  adoption: 0.9660\n",
      "  irrelevant: 0.9658\n",
      "  involve: 0.9658\n",
      "Most similar words to 'swaraj':\n",
      "  independence: 0.9208\n",
      "  win: 0.9171\n",
      "  attainment: 0.9169\n",
      "  freedom: 0.9109\n",
      "  winning: 0.9024\n",
      "  attain: 0.9007\n",
      "  complete: 0.9006\n",
      "  achieve: 0.8990\n",
      "  self-purification: 0.8988\n",
      "  achieved: 0.8941\n",
      "Most similar words to 'British':\n",
      "  Empire: 0.8518\n",
      "  Imperial: 0.8255\n",
      "  Chinese: 0.8224\n",
      "  Burma: 0.8209\n",
      "  Transvaal: 0.8184\n",
      "  States: 0.8162\n",
      "  Portuguese: 0.8158\n",
      "  territory: 0.8102\n",
      "  treaty: 0.8097\n",
      "  Crown: 0.8091\n",
      "Most similar words to 'Nehru':\n",
      "  Memorial: 0.9127\n",
      "  Museum: 0.9024\n",
      "  Papers: 0.8891\n",
      "  Motilal: 0.8843\n",
      "  Lal: 0.8749\n",
      "  Smarak: 0.8715\n",
      "  Spiegel: 0.8714\n",
      "  Gopichand: 0.8711\n",
      "  Rameshwari: 0.8710\n",
      "  Pandit: 0.8709\n",
      "Most similar words to 'Gandhi':\n",
      "  Mahatma: 0.8687\n",
      "  Narandas: 0.8107\n",
      "  Maganlal: 0.7921\n",
      "  Gandhiâ€”The: 0.7904\n",
      "  Chamberlain: 0.7896\n",
      "  Gidwani: 0.7876\n",
      "  Kallenbach: 0.7864\n",
      "  Joshi: 0.7827\n",
      "  Patel: 0.7824\n",
      "  Andrews: 0.7793\n"
     ]
    }
   ],
   "source": [
    "# Find the most similar words to keyword list\n",
    "\n",
    "keywords = ['woman', 'India', 'corruption', 'swaraj', 'British', 'Nehru', 'Gandhi']\n",
    "\n",
    "similar_words = []\n",
    "for keyword in keywords:\n",
    "    try:\n",
    "        similar = model.wv.most_similar(keyword, topn=10)\n",
    "        similar_words.append((keyword, similar))\n",
    "        print(f\"Most similar words to '{keyword}':\")\n",
    "        for word, similarity in similar:\n",
    "            print(f\"  {word}: {similarity:.4f}\")\n",
    "    except KeyError:\n",
    "        print(f\"Keyword '{keyword}' not found in the model vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8cff54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector representation of 'corruption': [-0.3071846  -0.16986261  0.24382703  0.44948947 -0.33338794 -0.5825755\n",
      "  0.42599824  0.510166   -0.16396478 -0.5995941  -0.03911551 -0.427977\n",
      " -0.459653    0.11343037  0.10349775 -0.00396546  0.2117004  -0.4766146\n",
      " -0.19187829 -0.3733604   0.2986089   0.26503122  0.34738562 -0.4482629\n",
      "  0.2724958  -0.13281159 -0.32682085 -0.19033614 -0.08992137  0.23118359\n",
      "  0.45771712  0.08356082  0.28556418 -0.1611731   0.07988834  0.22735682\n",
      "  0.19347295 -0.2786804  -0.13479409 -0.44878632 -0.3034332  -0.37835\n",
      " -0.463339    0.18419956  0.2734431   0.2562554  -0.25737113  0.14293516\n",
      "  0.37513703  0.296042   -0.06384351 -0.10036561 -0.06549443 -0.39084625\n",
      "  0.35873514  0.35416475  0.00427752 -0.1998214  -0.0527464   0.13878179\n",
      " -0.2508684   0.39061058 -0.16396904 -0.16918594 -0.4966776   0.2916621\n",
      " -0.0342145   0.1720171  -0.13038482  0.05199529  0.0248208  -0.06326141\n",
      "  0.3163952  -0.35612255  0.57987964  0.57908297  0.16003266 -0.30521813\n",
      " -0.2584842  -0.33131263 -0.0612901   0.06035193 -0.00730839  0.5726953\n",
      "  0.23425363  0.23768249  0.1214238   0.2229348   0.05612409  0.06147572\n",
      "  0.233639   -0.03861772  0.08551953  0.14863409  0.49963173  0.26505375\n",
      " -0.04686719 -0.3121821   0.2633036  -0.21289076]\n"
     ]
    }
   ],
   "source": [
    "# Take user input for a word\n",
    "word = input(\"Enter a word to find its vector representation: \")\n",
    "\n",
    "# Get the vector representation of the word\n",
    "try:\n",
    "    word_vector = model.wv[word]\n",
    "    print(f\"Vector representation of '{word}': {word_vector}\")\n",
    "    # Find the most similar words to input\"\n",
    "    similar_words = model.wv.most_similar(word, topn=10)\n",
    "except KeyError:\n",
    "    print(f\"'{word}' not found in the vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90eded23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to woman:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to list.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMost similar words to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m similar_word, similarity \u001b[38;5;129;01min\u001b[39;00m similar_words:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilar_word\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilarity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to list.__format__"
     ]
    }
   ],
   "source": [
    "for word in keywords:\n",
    "    print(f\"Most similar words to {word}:\")\n",
    "    for similar_word, similarity in similar_words:\n",
    "        print(f\"{similar_word}: {similarity:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
